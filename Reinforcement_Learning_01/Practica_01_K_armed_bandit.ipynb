{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**K-armed bandit problem**"],"metadata":{"id":"hetTsMN4bNDy"}},{"cell_type":"markdown","source":["##**Definir probabilidad**"],"metadata":{"id":"JmeI50JtbpTW"}},{"cell_type":"markdown","source":["En este notebook veremos cómo resolver el problema del k-armed bandit (o multi-armed bandit) utilizando los conceptos básicos del Reinforcement Learning.\n","\n","Para empezar establecemos la probabilidad de ganar de una máquina tragamonedas. En realidad, el jugador no conoce a priori la probabilidad de ganar de la máquina."],"metadata":{"id":"PUQPqJgxZaFn"}},{"cell_type":"code","metadata":{"id":"F2ZTR4rgovNZ"},"source":["#probabilidad de ganar de una máquina\n","prob_win = 0.6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Importamos la librería random, que devuleve un número al azar entre 0 y 1."],"metadata":{"id":"k3-z8-wwb_gg"}},{"cell_type":"code","metadata":{"id":"3uIdvmOpgRBM"},"source":["import random as rd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWjQnAQWpIf-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05e016d3-5863-4ada-cef3-a9ff2bb45f4b","executionInfo":{"status":"ok","timestamp":1709924905408,"user_tz":-60,"elapsed":210,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(30)\n","rd.random()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5390815646058106"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["Es el momento de jugar.\n","\n","La probabilidad de ganar equivale a la probabilidad de que el número random sea inferior al que hemos definido al principio."],"metadata":{"id":"TOZS41o8cSKO"}},{"cell_type":"code","metadata":{"id":"VZiFslk7psNT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924907992,"user_tz":-60,"elapsed":239,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"d10d6956-7f96-403f-968b-4dc15d758d40"},"source":["#si rd.random() < 0.6, devuelve True. Esto ocurrirá el 60% de las veces\n","rd.seed(30)\n","\n","rd.random() < prob_win"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"28s40Z0fp9FL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924910260,"user_tz":-60,"elapsed":861,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"f92ffeae-0850-4d9a-d42a-45735bf6caa7"},"source":["#si True ganamos, si False perdemos\n","rd.seed(30)\n","\n","if rd.random() < prob_win:\n","  print('win')\n","else:\n","  print('lose')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["win\n"]}]},{"cell_type":"code","metadata":{"id":"wj5XierPqJjH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924912703,"user_tz":-60,"elapsed":222,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"389376ca-eaa6-499d-9977-f687c831a4f2"},"source":["#jugamos 10 veces\n","rd.seed(30)\n","\n","for i in range(10):\n","  if rd.random() < prob_win:\n","    print('win')\n","  else:\n","    print('lose')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["win\n","win\n","win\n","lose\n","win\n","win\n","win\n","lose\n","lose\n","win\n"]}]},{"cell_type":"markdown","source":["##**Definir recompensa**"],"metadata":{"id":"O4p7l7Ed-bt8"}},{"cell_type":"code","metadata":{"id":"qj0QBjiwqaFc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924914619,"user_tz":-60,"elapsed":209,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"dc74bb8a-b122-45cb-c10d-56cda7d1e201"},"source":["#guardamos los resultados en una lista llamada \"list_rewards\"\n","rd.seed(30)\n","\n","list_rewards = []\n","\n","for i in range(10):\n","  if rd.random() < prob_win:\n","    list_rewards.append('win')\n","  else:\n","    list_rewards.append('lose')\n","\n","list_rewards"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['win', 'win', 'win', 'lose', 'win', 'win', 'win', 'lose', 'lose', 'win']"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["Para establecer si ganamos o perdemos, estamos usando siempre la misma expresión:\n","\n","\n","```\n","rd.random() < prob_win\n","```\n","Definimos una función llamada \"get_reward\", que nos da reward 1 si ganamos y 0 si perdemos.\n"],"metadata":{"id":"NmnHvVfUdGfI"}},{"cell_type":"code","metadata":{"id":"qoP6GObgrsLU"},"source":["#definimos la función \"get_reward\"\n","def get_reward(prob_win):\n","  if rd.random() < prob_win:\n","    r = 1 #win\n","  else:\n","    r = 0 #lose\n","  return r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ePpZJHqsfdX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924919386,"user_tz":-60,"elapsed":296,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"6be69ad1-ee29-4636-8bd8-185b471bbae5"},"source":["#llamamos la función y la ejecutamos 10 veces\n","rd.seed(30)\n","\n","list_rewards = [get_reward(prob_win) for i in range(10)]\n","list_rewards"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 1, 1, 0, 1, 1, 1, 0, 0, 1]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"-Q9nWMW06i0L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924921469,"user_tz":-60,"elapsed":205,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"9ddb20cd-d443-47c9-9c2c-c9ef39be4750"},"source":["#en vez de guardar la lista de recompensas, cálculamos la recompensa total cómo suma de las 10 recompensas\n","rd.seed(30)\n","\n","total_reward = 0\n","iteration = 0\n","\n","for i in range(10):\n","  iteration += 1\n","  r = get_reward(prob_win)\n","  print('Resultado iteración {0}: {1}'.format(iteration, r))\n","\n","  total_reward += r\n","\n","print('Recompensa total: {0}'.format(total_reward))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Resultado iteración 1: 1\n","Resultado iteración 2: 1\n","Resultado iteración 3: 1\n","Resultado iteración 4: 0\n","Resultado iteración 5: 1\n","Resultado iteración 6: 1\n","Resultado iteración 7: 1\n","Resultado iteración 8: 0\n","Resultado iteración 9: 0\n","Resultado iteración 10: 1\n","Recompensa total: 7\n"]}]},{"cell_type":"markdown","source":["##**Definir action-value**"],"metadata":{"id":"zyYKqOSI-gTF"}},{"cell_type":"markdown","source":["Introducimos el concepto de \"expected prize action/expected return/action value\": la probabilidad esperada de ganar."],"metadata":{"id":"xa42Hw_1X8Y9"}},{"cell_type":"markdown","source":["*Veámoslo primero en las slides...*"],"metadata":{"id":"JpOAxLlgXlwD"}},{"cell_type":"markdown","source":["Inicializamos la probabilidad esperada de ganar a 1\n","\n","```\n","expected_prize_action = expected_prize_action + (r-expected_prize_action) / iteration\n","```\n","Recordemos que el jugador no conoce a priori la probabilidad de ganar de la máquina; lo que puede hacer para intentar deducirla es jugar varias veces y actualizar sus expectativas en función de los resultados obtenidos."],"metadata":{"id":"nCh8m8bBeEJR"}},{"cell_type":"code","metadata":{"id":"Bxg-_y83683x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709924928009,"user_tz":-60,"elapsed":210,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"5316d93b-803e-4f24-c5bc-a4f88dcd3821"},"source":["rd.seed(30)\n","\n","total_reward = 0\n","iteration = 0\n","expected_prize_action = 1\n","\n","for i in range(10):\n","  iteration += 1\n","  r = get_reward(prob_win)\n","  print('\\nResultado iteración {0}: {1}'.format(iteration, r))\n","\n","  total_reward += r\n","\n","  expected_prize_action = expected_prize_action + (r-expected_prize_action) / iteration\n","  print('Probabilidad esperada: {0}'.format(round(expected_prize_action,2)))\n","\n","print('\\nRecompensa total: {0}'.format(total_reward))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultado iteración 1: 1\n","Probabilidad esperada: 1.0\n","\n","Resultado iteración 2: 1\n","Probabilidad esperada: 1.0\n","\n","Resultado iteración 3: 1\n","Probabilidad esperada: 1.0\n","\n","Resultado iteración 4: 0\n","Probabilidad esperada: 0.75\n","\n","Resultado iteración 5: 1\n","Probabilidad esperada: 0.8\n","\n","Resultado iteración 6: 1\n","Probabilidad esperada: 0.83\n","\n","Resultado iteración 7: 1\n","Probabilidad esperada: 0.86\n","\n","Resultado iteración 8: 0\n","Probabilidad esperada: 0.75\n","\n","Resultado iteración 9: 0\n","Probabilidad esperada: 0.67\n","\n","Resultado iteración 10: 1\n","Probabilidad esperada: 0.7\n","\n","Recompensa total: 7\n"]}]},{"cell_type":"markdown","source":["*Comprobemos estos resultados en las slides...*"],"metadata":{"id":"reiLVxAdbZwJ"}},{"cell_type":"markdown","source":["##**Jugar con 3 máquinas**"],"metadata":{"id":"a9O4plxa-mix"}},{"cell_type":"markdown","source":["Ahora vamos a jugar con 3 máquinas"],"metadata":{"id":"667Gq-6bgiYU"}},{"cell_type":"code","metadata":{"id":"T2CAT4ht6AgF"},"source":["#probabilidades de éxito de 3 máquinas\n","prob_win = [0.9, 0.5, 0.1]\n","n_machines = len(prob_win)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Probamos nuestra función \"get_reward\" para las 3 máquinas:"],"metadata":{"id":"PcLNFHqLdtUK"}},{"cell_type":"code","metadata":{"id":"3sgv9joitr_p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ab786f8-b832-4551-e588-d9ebb9372d2e","executionInfo":{"status":"ok","timestamp":1709925036670,"user_tz":-60,"elapsed":220,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","for index in range(0,n_machines): # index es la máquina que elegimos\n","  list_rewards = [get_reward(prob_win[index]) for i in range(10)]\n","  print('Recompensa máquina {0}: {1}'.format(index+1, list_rewards))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recompensa máquina 1: [1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n","Recompensa máquina 2: [0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n","Recompensa máquina 3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"markdown","source":["EMPEZAMOS A JUGAR!\n","\n","Elegimos una máquina al azar:"],"metadata":{"id":"fvrfRsuVdxLm"}},{"cell_type":"code","metadata":{"id":"ga45W7s7tPFZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"50e7f03c-99f7-4086-c80d-d64c42abd3eb","executionInfo":{"status":"ok","timestamp":1709925384579,"user_tz":-60,"elapsed":219,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","index = rd.randint(0,n_machines-1)\n","print('Máquina {0}'.format(index+1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Máquina 1\n"]}]},{"cell_type":"code","metadata":{"id":"roBkIF4uv-qM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"65f2a9a8-7a4f-46c6-c5cb-e9cae4a5bf2d","executionInfo":{"status":"ok","timestamp":1709925399899,"user_tz":-60,"elapsed":241,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","list_rewards = [get_reward(prob_win[index]) for i in range(10)]\n","print('Recompensa máquina {0}: {1}'.format(index+1,list_rewards))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recompensa máquina 1: [1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n"]}]},{"cell_type":"markdown","source":["Cálculamos la recompensa total como suma de 100 recompensas:"],"metadata":{"id":"THfsv147d9Jk"}},{"cell_type":"code","metadata":{"id":"gpNIsScXw9t3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"50867dfd-d9d1-4085-fe48-44f71e75b1d0","executionInfo":{"status":"ok","timestamp":1709925662490,"user_tz":-60,"elapsed":203,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","total_reward = 0\n","\n","for i in range(100):\n","  r = get_reward(prob_win[index])\n","  total_reward += r\n","\n","print('Recompensa total máquina {0}: {1}'.format(index+1,total_reward))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recompensa total máquina 1: 83\n"]}]},{"cell_type":"markdown","source":["Calculámos la recompensa total para las 3 máquinas:"],"metadata":{"id":"pTdn2ahbeEs9"}},{"cell_type":"code","metadata":{"id":"fASml0fyyHSq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"31aad728-d9c7-426f-e6c4-33b6011762b6","executionInfo":{"status":"ok","timestamp":1709925798706,"user_tz":-60,"elapsed":219,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","for index in range(0,n_machines): #iteramos por cada máquina\n","  total_reward = 0 #importante! la recompensa total se tiene que reiniciar para cada máquina\n","\n","  for i in range(100):\n","    r = get_reward(prob_win[index])\n","    total_reward += r\n","\n","  print('Recompensa total máquina {0}: {1}'.format(index+1,total_reward))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recompensa total máquina 1: 83\n","Recompensa total máquina 2: 42\n","Recompensa total máquina 3: 14\n"]}]},{"cell_type":"markdown","source":["Calculamos la recompensa total y la probabilidad esperada para las 3 máquinas:"],"metadata":{"id":"2czipOiLeRRh"}},{"cell_type":"code","metadata":{"id":"SgpC5Y0L-UrN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a31721d1-1b7d-4321-f006-03413071041f","executionInfo":{"status":"ok","timestamp":1709926346462,"user_tz":-60,"elapsed":220,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","for index in range(0,n_machines):\n","  total_reward = 0\n","  expected_prize_action = 1\n","  iteration = 0\n","\n","  for i in range(100): # Probar con más iteraciones\n","    iteration += 1\n","    r = get_reward(prob_win[index])\n","    total_reward += r\n","    expected_prize_action = expected_prize_action + (r-expected_prize_action) / iteration # formula\n","\n","  print('Máquina {0}: recompensa total {1}, probabilidad esperada {2}'.format(index+1,total_reward,round(expected_prize_action,2)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Máquina 1: recompensa total 83, probabilidad esperada 0.83\n","Máquina 2: recompensa total 42, probabilidad esperada 0.42\n","Máquina 3: recompensa total 14, probabilidad esperada 0.14\n"]}]},{"cell_type":"markdown","source":["Ahora jugaremos 1000 veces, cada vez eligiendo una máquina distinta (al azar)."],"metadata":{"id":"i14vY9UUehCr"}},{"cell_type":"code","metadata":{"id":"07w-rCXGz_Jp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b919d665-00b2-462b-995a-5b34c0a9a1a3","executionInfo":{"status":"ok","timestamp":1709927600674,"user_tz":-60,"elapsed":233,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","#definimos la recompensa total\n","total_reward = 0\n","\n","#número de veces que hemos jugado\n","i = 0\n","\n","#número de veces que hemos jugado con cada máquina\n","iterations_machine = [0,0,0]\n","\n","#inicializamos las probabilidades de ganar. Antes de empezar, es igual para todas las máquinas\n","expected_prize_action = [1,1,1]\n","\n","for x in range(1000):\n","\n","  #index es la máquina que estamos jugando en esta iteración\n","  index=rd.randint(0,n_machines-1)\n","\n","  #esta parte emula si ganamos o perdemos\n","  r = get_reward(prob_win[index])\n","\n","  #se actualiza la recompensa total\n","  total_reward += r\n","\n","  #actualizamos número de veces que hemos jugado\n","  i += 1\n","\n","  #actualizamos el número de veces que hemos jugado la máquina elegida\n","  iterations_machine[index] += 1\n","\n","  #actualizamos la probabilidad esperada de ganar para la máquina elegida\n","  expected_prize_action[index] = expected_prize_action[index] + (r-expected_prize_action[index]) / iterations_machine[index]\n","\n","print('Hemos jugado {0} veces.'.format(i))\n","print('La recompensa total es de {0} puntos.'.format(total_reward))\n","for index in range(0,n_machines):\n","  print('La máquina {0} ha sido elegida {1} veces. Su probabilidad esperada es de {2}'.format(index+1, iterations_machine[index], round(expected_prize_action[index],2)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hemos jugado 1000 veces.\n","La recompensa total es de 513 puntos.\n","La máquina 1 ha sido elegida 322 veces. Su probabilidad esperada es de 0.92\n","La máquina 2 ha sido elegida 349 veces. Su probabilidad esperada es de 0.52\n","La máquina 3 ha sido elegida 329 veces. Su probabilidad esperada es de 0.11\n"]}]},{"cell_type":"markdown","source":["*Veamos los resultados en las slides...*"],"metadata":{"id":"_OYym2llf_Iu"}},{"cell_type":"markdown","source":["##**Definir greedy-policy**"],"metadata":{"id":"JhOkrONG-3HN"}},{"cell_type":"markdown","source":["¿Y si no quisieramos elegir una máquina al azar, sino la que nos da mayor recompensa?"],"metadata":{"id":"mJQIfsy7fElw"}},{"cell_type":"code","metadata":{"id":"JbnUU6RCBUAN"},"source":["#definimos nuestra función \"greedy\", que elige la máquina con mayor probabilidad esperada de ganar\n","def greedy(expected_prize_action): # expected_prize_action son las probabilidades estimadas de ganar de cada máquina\n","    index=np.argmax(expected_prize_action)\n","    return index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NA1g-0nA3ZB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709945668469,"user_tz":-60,"elapsed":224,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"49f2fd55-6008-4dad-9b96-043861affb53"},"source":["rd.seed(51)\n","\n","#definimos la recompensa total\n","total_reward = 0\n","\n","#número de veces que hemos jugado\n","i = 0\n","\n","#número de veces que hemos jugado cáda máquina\n","iterations_machine = [0,0,0] # inicializamos a 0\n","\n","#inicializamos las probabilidades de ganar. Antes de empezar, es igual para todas las máquinas\n","expected_prize_action=[1,1,1] # inicializamos a 1\n","\n","for x in range(1000):\n","\n","  #index es la máquina que estamos jugando en esta iteración\n","  index = greedy(expected_prize_action) #elegimos la máquina que tiene mayor probabilidad esperada\n","\n","  #esta parte emula si ganamos o perdemos\n","  r = get_reward(prob_win[index])\n","\n","  #se actualiza la recompensa total\n","  total_reward += r\n","\n","  #actualizamos número de veces que hemos jugado\n","  i += 1\n","\n","  #actualizamos el número de veces que hemos jugado la máquina elegida\n","  iterations_machine[index] += 1\n","\n","  #actualizamos la probabilidad esperada de ganar para la máquina elegida\n","  expected_prize_action[index] = expected_prize_action[index] + (r-expected_prize_action[index]) / iterations_machine[index]\n","\n","print('Hemos jugado {0} veces.'.format(i))\n","print('La recompensa total es de {0} puntos.'.format(total_reward))\n","for index in range(0,n_machines):\n","  print('La máquina {0} ha sido elegida {1} veces. Su probabilidad esperada es de {2}'.format(index+1, iterations_machine[index], round(expected_prize_action[index],2)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hemos jugado 1000 veces.\n","La recompensa total es de 900 puntos.\n","La máquina 1 ha sido elegida 997 veces. Su probabilidad esperada es de 0.9\n","La máquina 2 ha sido elegida 2 veces. Su probabilidad esperada es de 0.5\n","La máquina 3 ha sido elegida 1 veces. Su probabilidad esperada es de 0.0\n"]}]},{"cell_type":"markdown","source":["*Veamos los resultados en las slides...*"],"metadata":{"id":"D6Wa2gSQgSRC"}},{"cell_type":"markdown","source":["##**Jugar con muchas máquinas**"],"metadata":{"id":"RWaES-wWBTto"}},{"cell_type":"markdown","source":["Si tenemos muchas máquinas, corremos el riesgo de no explorar."],"metadata":{"id":"zquXZmpDf3PQ"}},{"cell_type":"code","metadata":{"id":"5wkEJg3PC53f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7055b019-9244-4cb2-9b1e-878ba1eb9212","executionInfo":{"status":"ok","timestamp":1709945738315,"user_tz":-60,"elapsed":326,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}}},"source":["rd.seed(51)\n","\n","prob_win = [0.8, 0.4, 0.6, 0.85, 0.2, 0.75, 0.9, 0.55, 0.8, 0.6]\n","n_machines = len(prob_win)\n","\n","#definimos la recompensa total\n","total_reward = 0\n","\n","#número de veces que hemos jugado\n","i = 0\n","\n","#número de veces que hemos jugado cáda máquina\n","iterations_machine = np.zeros(n_machines) # inicializamos a 0\n","\n","#inicializamos las probabilidades de ganar. Antes de empezar, es igual para todas las máquinas\n","expected_prize_action = np.ones(n_machines) # inicializamos a 1\n","\n","#guardamos la máquina elegida en cada iteración en un vector\n","chosen_machine = []\n","\n","for x in range(1000):\n","\n","  #index es la máquina que estamos jugando en esta iteración\n","  index=greedy(expected_prize_action) #elegimos la máquina que tiene mayor probabilidad esperada\n","\n","  #esta parte emula si ganamos o perdemos\n","  r = get_reward(prob_win[index])\n","\n","  #se actualiza la recompensa total\n","  total_reward += r\n","\n","  #actualizamos número de veces que hemos jugado\n","  i += 1\n","\n","  #actualizamos el número de veces que hemos jugado la máquina elegida\n","  iterations_machine[index] += 1\n","\n","  #actualizamos la probabilidad esperada de ganar para la máquina elegida\n","  expected_prize_action[index] = expected_prize_action[index] + (r-expected_prize_action[index]) / iterations_machine[index]\n","\n","  #actualizamos el vector con la máquina elegida en esta iteración\n","  chosen_machine.append(index)\n","\n","\n","print('Hemos jugado {0} veces.'.format(i))\n","print('La recompensa total es de {0} puntos.'.format(total_reward))\n","for index in range(0,n_machines):\n","  print('La máquina {0} ha sido elegida {1} veces'.format(index+1, iterations_machine[index]))\n","\n","print('La máquina con mayor probabilidad real (máquina {0}) ha sido elegida correctamente {1} veces.'.format(np.argmax(prob_win)+1,chosen_machine.count(np.argmax(prob_win))))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hemos jugado 1000 veces.\n","La recompensa total es de 800 puntos.\n","La máquina 1 ha sido elegida 5.0 veces\n","La máquina 2 ha sido elegida 2.0 veces\n","La máquina 3 ha sido elegida 1.0 veces\n","La máquina 4 ha sido elegida 2.0 veces\n","La máquina 5 ha sido elegida 1.0 veces\n","La máquina 6 ha sido elegida 9.0 veces\n","La máquina 7 ha sido elegida 2.0 veces\n","La máquina 8 ha sido elegida 1.0 veces\n","La máquina 9 ha sido elegida 975.0 veces\n","La máquina 10 ha sido elegida 2.0 veces\n","La máquina con mayor probabilidad real (máquina 7) ha sido elegida correctamente 2 veces.\n"]}]},{"cell_type":"markdown","source":["*...Veamos los resultados en las slides*"],"metadata":{"id":"byGZ6LjyhJ13"}},{"cell_type":"markdown","source":["##**Exploration vs Explotation**"],"metadata":{"id":"GvxX8tjcBad_"}},{"cell_type":"code","metadata":{"id":"7hw8O9zaOqSC"},"source":["#trade-off entre explorar y explotar\n","def greedy_trade_off(exp_price,epsilon):\n","    if(rd.random() < epsilon):\n","            index=rd.randint(0,len(exp_price)-1) #explorar\n","    else:\n","        index=np.argmax(exp_price) #explotar\n","    return index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkSe-iR1PbEP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709946821853,"user_tz":-60,"elapsed":9,"user":{"displayName":"Javier Martí Isasi","userId":"03138589225676606967"}},"outputId":"b9f07a61-c323-42f1-edec-71fd87f46ad8"},"source":["rd.seed(51)\n","\n","prob_win = [0.8, 0.4, 0.6, 0.85, 0.2, 0.75, 0.9, 0.55, 0.8, 0.6]\n","n_machines = len(prob_win)\n","\n","#exploraremos el 15% de las veces\n","epsilon = 0.15\n","\n","#definimos la recompensa total\n","total_reward = 0\n","\n","#número de veces que hemos jugado\n","i = 0\n","\n","#número de veces que hemos jugado cáda máquina\n","iterations_machine = np.zeros(n_machines)\n","\n","#inicializamos las probabilidades de ganar. Antes de empezar, es igual para todas las máquinas\n","expected_prize_action = np.ones(n_machines)\n","\n","#guardamos la máquina elegida en cada iteración en un vector\n","chosen_machine = []\n","\n","for x in range(1000):\n","\n","  #index es la máquina que estamos jugando en esta iteración\n","  index = greedy_trade_off(expected_prize_action, epsilon) #elegimos la máquina que tiene mayor probabilidad esperada\n","\n","  #esta parte emula si ganamos o perdemos\n","  r = get_reward(prob_win[index])\n","\n","  #se actualiza la recompensa total\n","  total_reward += r\n","\n","  #actualizamos número de veces que hemos jugado\n","  i += 1\n","\n","  #actualizamos el número de veces que hemos jugado la máquina elegida\n","  iterations_machine[index] += 1\n","\n","  #actualizamos la probabilidad esperada de ganar para la máquina elegida\n","  expected_prize_action[index] = expected_prize_action[index] + (r-expected_prize_action[index]) / iterations_machine[index]\n","\n","  #actualizamos el vector con la máquina elegida en esta iteración\n","  chosen_machine.append(index)\n","\n","\n","print('Hemos jugado {0} veces.'.format(i))\n","print('La recompensa total es de {0} puntos.'.format(total_reward))\n","for index in range(0,n_machines):\n","  print('La máquina {0} ha sido elegida {1} veces'.format(index+1, iterations_machine[index]))\n","\n","print('La máquina con mayor probabiliad real (máquina {0}) ha sido elegida correctamente {1} veces.'.format(np.argmax(prob_win)+1,chosen_machine.count(np.argmax(prob_win))))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hemos jugado 1000 veces.\n","La recompensa total es de 856 puntos.\n","La máquina 1 ha sido elegida 16.0 veces\n","La máquina 2 ha sido elegida 15.0 veces\n","La máquina 3 ha sido elegida 17.0 veces\n","La máquina 4 ha sido elegida 21.0 veces\n","La máquina 5 ha sido elegida 19.0 veces\n","La máquina 6 ha sido elegida 19.0 veces\n","La máquina 7 ha sido elegida 840.0 veces\n","La máquina 8 ha sido elegida 16.0 veces\n","La máquina 9 ha sido elegida 20.0 veces\n","La máquina 10 ha sido elegida 17.0 veces\n","La máquina con mayor probabiliad real (máquina 7) ha sido elegida correctamente 840 veces.\n"]}]},{"cell_type":"markdown","source":["*...Veamos los resultados en las slides*"],"metadata":{"id":"i2ZYWLRRx9Xz"}}]}